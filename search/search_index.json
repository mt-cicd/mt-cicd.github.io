{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":"<p>\ud83d\udd0d Breakdown:</p> <p>\u2705 DevOps = the broader philosophy</p> <p>DevOps is a cultural and technical movement that aims to unify software development (Dev) and IT operations (Ops). Its goal is to:</p> <ul> <li>Improve collaboration between teams</li> <li>Automate processes</li> <li>Deliver software faster and more reliably</li> <li>Continuously monitor and improve systems</li> </ul> <p>\ud83d\udee0\ufe0f CI/CD = one key set of practices/tools inside DevOps</p> <p>CI/CD stands for:</p> <ul> <li>CI: Continuous Integration \u2014 developers frequently merge code into a shared repository, triggering automated builds/tests</li> <li>CD: Continuous Delivery or Deployment \u2014 automating the release of that code to staging or production</li> </ul> <p>CI/CD helps teams:</p> <ul> <li>Detect bugs early</li> <li>Automate repetitive manual processes</li> <li>Ship features faster and safer</li> </ul> <p>\ud83d\udcca Visual Analogy:</p> <pre><code>DevOps\n\u251c\u2500\u2500 CI/CD        \u2190 Automates build/test/deploy\n\u251c\u2500\u2500 Infrastructure as Code (IaC)\n\u251c\u2500\u2500 Monitoring &amp; Logging\n\u251c\u2500\u2500 Configuration Management\n\u251c\u2500\u2500 Incident Response\n\u2514\u2500\u2500 Collaboration &amp; Culture\n</code></pre> <p>\u2705 Summary:</p> Concept What it is Scope DevOps Culture + tools for fast, reliable delivery Broad CI/CD Specific tools/practices for automation Narrow, within DevOps <p></p>"},{"location":"#reference","title":"Reference","text":"<ul> <li>techicons.dev</li> <li>A Crash Course in CI/CD</li> </ul>"},{"location":"blog/","title":"Index","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2025/06/06/mkdocs-install-as-app-issue/","title":"Mkdocs Install as App Issue","text":"","tags":["Personal"]},{"location":"blog/2025/06/06/mkdocs-install-as-app-issue/#mkdocs-install-as-app-issue","title":"Mkdocs <code>Install as App</code> Issue","text":"<p>This is a common situation with Progressive Web Apps (PWAs) after uninstalling them.</p>","tags":["Personal"]},{"location":"blog/2025/06/06/mkdocs-install-as-app-issue/#overview","title":"Overview","text":"<p>Previous it shows Install App but after i uninstall and now trying to Install as App but it doesn't show me the Install as App option it only show Create shortcut</p> <p>Thanks for the clarification \u2014 this is a common situation with Progressive Web Apps (PWAs) after uninstalling them. Here's why you're seeing only \"Create shortcut\" instead of \"Install app\" now:</p>","tags":["Personal"]},{"location":"blog/2025/06/06/mkdocs-install-as-app-issue/#why-install-app-disappeared-after-uninstalling","title":"\ud83d\udd01 Why \"Install App\" disappeared after uninstalling","text":"<p>When you uninstall a PWA (by removing it from the home screen or app drawer), modern browsers \u2014 especially Chrome on Android \u2014 apply a cool-down period. This is meant to prevent users from being annoyed by frequent install prompts.</p> \u26a0\ufe0f What happens: <ul> <li>The browser remembers that you recently uninstalled the app.</li> <li>It suppresses the \"Install App\" option for a period (usually a few days).</li> <li>During this time, only \"Add to home screen\" or \"Create shortcut\" will appear.</li> </ul>","tags":["Personal"]},{"location":"blog/2025/06/06/mkdocs-install-as-app-issue/#how-to-solve-it","title":"\u2705 How to solve it","text":"<p>Here are ways to trigger \"Install app\" again:</p> Option 1: Wait <ul> <li>Wait a few days (usually 3\u20137) for the browser to reset its internal state.</li> <li>Visit the site regularly during this time \u2014 this can help Chrome consider it \u201cengaged.\u201d</li> </ul> Option 2: Manually trigger install prompt (developer method) <p>If you're the developer or have access to the site code:</p> <ol> <li> <p>Ensure your site has:</p> <ul> <li> <p>A proper <code>manifest.json</code></p> </li> <li> <p>A service worker registered</p> </li> </ul> </li> <li> <p>Add a custom install button using the <code>beforeinstallprompt</code> event.</p> Example JavaScript:<pre><code>let deferredPrompt;\nwindow.addEventListener(\"beforeinstallprompt\", (e) =&gt; {\n    e.preventDefault();\n    deferredPrompt = e;\n    // Show your custom install button\n    document.getElementById(\"installBtn\").style.display = \"block\";\n\n    document.getElementById(\"installBtn\").addEventListener(\"click\", () =&gt; {\n        deferredPrompt.prompt();\n\n        deferredPrompt.userChoice.then((choiceResult) =&gt; {\n            if (choiceResult.outcome === \"accepted\") {\n                console.log(\"App installed\");\n            } else {\n                console.log(\"User dismissed\");\n            }\n            deferredPrompt = null;\n        });\n    });\n});\n</code></pre> </li> </ol> Option 3: Clear browser data (if acceptable) <p>\u26a0\ufe0f This will reset other sites too:</p> <ul> <li>Go to your mobile browser \u2192 Settings \u2192 Site Settings \u2192 Storage or Cached Data</li> <li>Find your site and clear its data and cache</li> <li>Restart the browser and visit the site again</li> </ul> <p>\u2705 Also check:</p> <ul> <li>Is your site still served over HTTPS?</li> <li>Do you still have a valid <code>manifest.webmanifest</code> and <code>service-worker.js</code>?</li> <li>Test with Chrome <code>DevTools</code> \u2192 <code>Application tab</code> \u2192 See if your PWA is detected</li> </ul>","tags":["Personal"]},{"location":"docker/docker-compose/","title":"Docker Compose","text":""},{"location":"docker/docker-compose/#django-with-mysql","title":"<code>Django</code> with <code>MySql</code>","text":"<p>If you choose <code>Docker Compose</code> to deploy your Django web application along with a MySQL database, you would typically follow these steps:</p> <ul> <li><code>Dockerfile</code> for Django App:</li> </ul> <p>Here's a basic example of what a Dockerfile for a Django application might look like:</p> <pre><code>FROM python:3.9\n\nWORKDIR /app\n\nCOPY requirements.txt /app/\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . /app/\n\nCMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n</code></pre> <ul> <li><code>docker-compose.yml</code>:</li> </ul> <p>Below is an example <code>docker-compose.yml</code> file for a Django app with a MySQL database:</p> <pre><code>  version: '3'\n\n  services:\n  db:\n      image: mysql:5.7\n      restart: always\n      environment:\n      MYSQL_DATABASE: 'mydatabase'\n      MYSQL_USER: 'myuser'\n      MYSQL_PASSWORD: 'mypassword'\n      MYSQL_ROOT_PASSWORD: 'rootpassword'\n      ports:\n      - '3306:3306'\n\n  web:\n      build: .\n      command: python manage.py runserver 0.0.0.0:8000\n      volumes:\n      - .:/app\n      ports:\n      - '8000:8000'\n      depends_on:\n      - db\n</code></pre> <ul> <li>Django <code>Settings</code>:</li> </ul> <p>Make sure your Django application's settings are configured to use the MySQL database. You'll need to update the <code>DATABASES</code> setting in your Django <code>settings.py</code> file to point to the MySQL database container</p> <ul> <li>Run <code>Docker Compose</code>:</li> </ul> <p>Run docker-compose up in the directory containing your docker-compose.yml file. This command will start the containers defined in the docker-compose.yml file. Docker Compose will build the Docker images (if necessary) and start the containers for your Django app and MySQL database.</p> <ul> <li><code>Access</code> Your Application:</li> </ul> <p>Once Docker Compose has started the containers, you should be able to access your Django application by navigating to <code>http://localhost:8000</code> in your web browser.</p>"},{"location":"docker/docker/","title":"Docker","text":""},{"location":"docker/docker/#installation","title":"Installation","text":"<p>The core of Docker is made of the Docker engine, a single-host software daemon that allows you to create and manage containers. Before diving into using Docker, you need to install the Docker engine on a host, either your desktop, laptop, or a server.</p> <p>A <code>Dockerfile</code> is a manifest that describes how to build a container image. This is a core concept in Docker.</p> Abstract DockerfileTheoryPractical <pre><code># Use an existing image as a base\nFROM alpine:latest\n\n# Run a command in the container\nCMD [\"echo\", \"Hello, Jenkins!\"]\n</code></pre> <p><code>Docker</code>, <code>Docker Compose</code>, and <code>Docker Swarm</code> are all related tools in the Docker ecosystem, but they serve different purposes:</p> <ol> <li> <p>Docker:</p> <p>Docker is a platform and tool for building, distributing, and running <code>containers</code>. Containers allow developers to package an application with all of its dependencies into a standardized unit for software development. Docker provides the tools needed to create and manage these containers efficiently. With Docker, you can build container images, run containers from those images, and manage container lifecycles.</p> </li> <li> <p>Docker Compose:</p> <p>Docker Compose is a tool for defining and running <code>multi-container</code> Docker applications. It allows you to use a YAML file to configure the services that make up your application, including their dependencies, networking, and volumes. Docker Compose then takes care of starting, stopping, and managing all of these containers as a single application stack. It simplifies the process of managing complex applications composed of multiple interconnected containers.</p> </li> <li> <p>Docker Swarm:</p> <p>Docker Swarm is Docker's native clustering and <code>orchestration tool</code>. It allows you to create and manage a cluster of Docker nodes, turning them into a single virtual Docker engine. Docker Swarm enables you to deploy and manage multi-container applications across multiple hosts, providing features such as service scaling, rolling updates, and high availability. It simplifies the management of containerized applications at scale and provides built-in features for load balancing and service discovery.</p> </li> </ol> <p>In summary:</p> <ul> <li><code>Docker</code>: The core platform for building, distributing, and running containers.</li> <li><code>Docker Compose</code>: A tool for defining and managing multi-container applications using a YAML configuration file.</li> <li><code>Docker Swarm</code>: Docker's native clustering and orchestration tool for managing multi-container applications across multiple hosts.</li> </ul> <pre><code>$ sudo apt-get install &lt;docker.deb&gt;\n</code></pre> <p>Commands</p> bash<pre><code># List containers:\n$ docker containers ls\n\n# List only running container: (ps-process status)\n$ docker ps -a\n\n# List images:\n$ docker images\n</code></pre> <p>Restart Docker</p> bash<pre><code># To restart a Docker container based on an image\n\n# 1.Identify the Container:\n$ docker ps\n\n# 2. Restart the Container:\n$ docker restart &lt;container_id_or_name&gt;\n\n# 3. Verify Restart:\n$ docker ps\n</code></pre>"},{"location":"docker/docker/#clarifying-docker-terms","title":"Clarifying Docker terms","text":"Abstract <p>Docker Registry</p> <p>A Docker Registry is a place where Docker images can be stored in order to be publicly or privately found, accessed, and used by software developers worldwide for quickly crafting fresh and composite applications without any risks. Because all the stored images will have gone through multiple validations, verifications, and refinements, the quality of those images is really high. You can dispatch your Docker image to the registry so that it is registered and deposited using the <code>docker push</code> subcommand. You can download Docker images from the registry using the <code>docker pull</code> subcommand.</p> <p>Docker Registry could be hosted by a third party as a public or private registry, like one of the following registries:</p> <ul> <li>Docker Hub</li> <li>Quay</li> <li>Google Container Registry</li> <li>AWS Container Registry</li> </ul> <p>Every institution, innovator, and individual can have their own Docker Registry to stock up their images for internal and/or external access and usage.</p> <ul> <li>Learning Docker Second Edition by Jeeva S. Chelladhurai, pg:31</li> </ul>"},{"location":"docker/docker/#nginx-engine-x-web-server","title":"nginx (Engine X) <code>web server</code>","text":"Abstract TheoryPractical bash<pre><code>sudo apt update\nsudo apt install nginx\n</code></pre> <p><code>/etc/nginx/nginx.conf</code></p> <p>The server_name directive in Nginx should specify only the domain name or names without the protocol (e.g., <code>http://</code>). Therefore, you need to modify your configuration like this:</p> nginx<pre><code>http {\n    server {\n        listen 9000;\n        server_name generic-info.ispl.com.np;\n\n        location / {\n        # Jenkins running on port 9000\n        proxy_pass http://10.114.0.175:9000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n\n    server {\n        listen 8080;\n        server_name generic-info.ispl.com.np;\n\n        location / {\n            # Portainer running on port 8080\n            proxy_pass http://10.114.0.175:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n}\n</code></pre> <p>After making this change, you should test the configuration to ensure there are no syntax errors:</p> bash<pre><code>sudo nginx -t\n</code></pre> <p>If the test is successful, reload Nginx to apply the changes:</p> bash<pre><code>sudo systemctl reload nginx\n</code></pre> <p>This should resolve the issue, and Nginx should be able to start without errors.</p> Using Paths to Differentiate Services <p>If Hostnames Are Not Available</p> <p>If you cannot use different hostnames, you will need to use different ports or subpaths as described in previous responses.</p> <pre><code>http {\n    server {\n        listen 80;\n        # No server_name specified\n\n        location /jenkins/ {\n            # Jenkins running on port 9000\n            proxy_pass http://10.114.0.175:9000/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            rewrite ^/jenkins(.*) $1 break;\n        }\n\n        location /portainer/ {\n            # Portainer running on port 8080\n            proxy_pass http://10.114.0.175:8080/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            rewrite ^/portainer(.*) $1 break;\n        }\n    }\n}\n</code></pre> <p>Explanation</p> <ul> <li>Single Server Block: Only one server block is needed, listening on port 80.</li> <li>Path-Based Routing: Requests to /jenkins are routed to Jenkins running on port 9000, and requests to /portainer are routed to Portainer running on port 8080.</li> <li>Rewrite Directive: The rewrite directive ensures that the backend service receives the correct path.</li> </ul> <p>Access URLs</p> <ul> <li>Jenkins: <code>http://&lt;your-server-ip&gt;/jenkins</code></li> <li>Portainer: <code>http://&lt;your-server-ip&gt;/portainer</code></li> </ul> same port <p>To serve both Jenkins and Portainer on the same port (port 80) without using subpaths like /jenkins and /portainer, you need to use different hostnames. Each service will be accessible via a different domain or subdomain. This approach requires DNS configuration to resolve different hostnames to your server's IP address.</p> <pre><code>http {\n    server {\n        listen 80;\n        server_name jenkins.example.com;\n\n        location / {\n            # Jenkins running on port 9000\n            proxy_pass http://10.114.0.175:9000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n\n    server {\n        listen 80;\n        server_name portainer.example.com;\n\n        location / {\n            # Portainer running on port 8080\n            proxy_pass http://10.114.0.175:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n}\n</code></pre> Different Port <pre><code>http {\n    server {\n        listen 80;\n        # No server_name specified\n\n        location / {\n            # Jenkins running on port 9000\n            proxy_pass http://10.114.0.175:9000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n\n    server {\n        listen 81;\n        # No server_name specified\n\n        location / {\n            # Portainer running on port 8080\n            proxy_pass http://10.114.0.175:8080;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n}\n</code></pre>"},{"location":"docker/docker/#docker-images","title":"Docker Images","text":"Abstract TheoryPracticalDangling images bash<pre><code># List Docker images\n$ docker images\n\n# Remove Docker image by ID\n$ docker rmi &lt;image_id&gt;\n\n# Remove Docker image by repository and tag\n$ docker rmi &lt;repository_name&gt;:&lt;tag&gt;\n\n# Forcefully remove images\n$ docker rmi -f &lt;image_id&gt;\n# or\n$ docker rmi --force &lt;image_id&gt;\n</code></pre> <p>Create Docker Image</p> <p>When working with Docker, you typically create an image first and then use that image to create containers.</p> <ol> <li> <p>Create Image:</p> <p>An image is like a template that contains the filesystem and configuration needed to run a container. You define an image using a <code>Dockerfile</code>, which specifies the instructions to build the image. You use the docker build command to create an image from a Dockerfile.</p> </li> <li> <p>Create Container:</p> <p>Once you have an image, you can create one or more containers from it. A container is a running instance of an image. You use the docker run command to create and start a container from an image. Each container runs in isolation from other containers but can communicate with them if configured to do so.</p> </li> </ol> <p>Here's a basic sequence of commands:</p> <ol> <li>Create the image:</li> </ol> <pre><code>$ docker build -t my-image .\n</code></pre> <ol> <li>Run a container based on that image:</li> </ol> <pre><code>$ docker run --name my-container my-image\n</code></pre> <p>So, to summarize, first, you build an image using a <code>Dockerfile</code>, then you create and run containers based on that image.</p> <p>Dangling images are layers that have no relationship to any tagged images. They no longer serve a purpose and consume disk space.</p> <p>Dangling images are created while creating new build of a image without renaming/updating the version of the image. So that the old image are converted into dangling images.</p> <pre><code># List Dangling images\n$ docker images -f dangling=true\n\n# Remove Dangling images\n$ docker rmi $(docker images -f dangling=true -q)\n\n##\n# To remove all dangling images.\n$ docker image prune\n\n# To remove all images which aren't used by existing containers, use the -a flag:\n$ docker image prune -a\n\n# To remove all stopped containers.\n$ docker container prune\n\n# To removes stopped containers older than 24 hours:\n$ docker container prune --filter \"until=24h\"\n\n# To remove all volumes not used by at least one container.\n$ docker volume prune\n\n# To remove all networks not used by at least one container.\n$ docker network prune\n\n# The docker system prune command is a shortcut that prunes images, containers, and networks.\n# Volumes aren't pruned by default, and you must specify the --volumes flag for docker system prune to prune volumes.\n\n# To prune images, containers and network\n$ docker system prune\n\n# To also prune volumes, add the --volumes flag:\n$ docker system prune --volumes\n</code></pre> <ul> <li>Remove unnecessary images</li> <li>Docker container and image prune</li> </ul>"},{"location":"docker/docker/#docker-container","title":"Docker Container","text":"Abstract TheoryPracticalAdditional <p>Create Docker Container</p> <p>example of creating a new container:</p> bash<pre><code># syntax\n# 1. Run a new container with the new image:\n$ docker run --name &lt;container_name&gt; -d &lt;new_image_name&gt;\n\n# 2. Stop the existing container:\n$ docker stop &lt;container_name_or_id&gt;\n\n# 3. Remove the existing container (optional):\n$ docker rm &lt;container_name_or_id&gt;\n\n# example\n$ docker run --name my-container -d my-image\n</code></pre> <ul> <li><code>--name my-container</code> sets the name of the container to my-container.</li> <li><code>-d</code> runs the container in detached mode (in the background).</li> <li><code>my-image</code> is the name of the image from which to create the container.</li> </ul> <p>This command will create a new container using the specified image. If the image is not available locally, Docker will automatically pull it from a registry like Docker Hub before creating the container.</p> <p>After running the command, you can use <code>docker ps</code> to see the list of running containers.</p> <p>Check the IP Address of the Docker Container</p> bash<pre><code>docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' &lt;container-name&gt;\n</code></pre> <p>Then try accessing the site using <code>curl</code> with the <code>IP address</code> and the <code>mapped port</code> (<code>8082</code> in this case).</p> <p>if you want to check if a container named my_container is using any volumes:</p> bash<pre><code>docker inspect &lt;my_container&gt; | grep Mounts\n</code></pre> bash<pre><code>docker run -d \\\n-p 8080:8080 \\\n-p 50000:50000 \\\n--name jenkins \\\n--restart unless-stopped \\\n-v generic-volume:/var/jenkins_home/generic-volume \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\njenkins/jenkins:lts\n\ndocker run -d \\\n-p 8080:8080 \\\n-p 50000:50000 \\\n--name jenkins \\\n--restart unless-stopped \\\n-v generic-volume:/var/jenkins_home/generic-volume \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\nmy-jenkins\n</code></pre>"},{"location":"docker/docker/#docker-volume","title":"Docker Volume","text":"Abstract TheoryPracticalAdditional bash<pre><code># List Volumes in Use:\n$ docker volume ls\n\n# list all containers to find out which volumes are in use:\n$ docker ps -a\n\n# delete the volumes\n$ docker volume rm &lt;volume_name_or_id&gt;\n\n# delete volumes along with the containers that use them\n$ docker rm -v &lt;container_name_or_id&gt;\n</code></pre> <p>Recap Docker Volume</p> <p>In a previous chapter, we used the \"<code>-v</code>\" option to a \"<code>docker run</code>\" command to declare that we wanted to use a volume with a container. The abbreviated \"<code>-v</code>\" option is exactly the same as the \"<code>--volume</code>\" option. However, the newer and preferred way to mount volumes in a container is the \"<code>--mount</code>\" option. Docker recommends that you use \"<code>--mount</code>\" instead of \"<code>-v</code>\" or \"<code>--volume</code>\", as their research has shown \"<code>--mount</code>\" is easier to use. However, if you are an old Docker user like myself, then you're probably accustomed to using and seeing \"<code>-v</code>\". In any case, either works, but we will focus on \"<code>--mount</code>\", as it\u2019s the recommended way.</p> <pre><code>$ docker run -d --name withvolume --mount source=mydata1,destination=/root/volume nginx\n\n#\ndocker run -d --name withvolume2 --mount src=mydata1,dst=/root/volume nginx\n\n$ docker run -dit --name ephemeral --mount type=tmpfs,destination=/root/volume nginx\n</code></pre> <ul> <li>Docker: A project based learning</li> <li>Publish Docker image to Dockerhub using Jenkins Pipeline</li> <li>Build a Docker Jenkins Pipeline to Implement CI/CD Workflow</li> </ul>"},{"location":"docker/docker/#portainer","title":"Portainer","text":"Abstract TheoryPracticalAdditional <p>Docker pull Command</p> bash<pre><code>$ docker pull portainer/portainer-ce\n</code></pre> <p>After installing Portainer in Docker on a Linux server, you can run it by executing the Docker run command with appropriate options. Here's how you can do it:</p> <ol> <li> <p>Open a Terminal:</p> <p>Log in to your Linux server via SSH or open a terminal window if you're working directly on the server.</p> </li> <li> <p>Run Portainer Container:</p> <p>Use the following command to start the Portainer container:</p> bash<pre><code>sudo docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce\n</code></pre> <p>Explanation of options:</p> <ul> <li> <p><code>-d</code>: Run the container in detached mode (in the background).</p> </li> <li> <p><code>-p 9000:9000</code>: Map port 9000 on the host to port 9000 inside the container. This allows you to access Portainer's web interface on port 9000 of your server.</p> </li> <li> <p><code>--name portainer</code>: Assign the name \"portainer\" to the container.</p> </li> <li> <p><code>--restart always</code>: Ensure that the container restarts automatically if it stops.</p> </li> <li> <p><code>-v /var/run/docker.sock:/var/run/docker.sock</code>: Mount the Docker socket inside the container, allowing Portainer to communicate with the Docker daemon.</p> </li> </ul> </li> <li> <p>Verify Portainer Container:</p> <p>You can verify that the Portainer container is running by executing the following command:</p> bash<pre><code>$ sudo docker ps\n</code></pre> <p>This command will list all running containers, and you should see an entry for the Portainer container.</p> </li> <li> <p>Access Portainer Web Interface:</p> <p>Once the Portainer container is running, you can access its web interface by opening a web browser and navigating to:</p> bash<pre><code>http://your_server_ip:9000\n</code></pre> <p>Replace <code>your_server_ip</code> with the <code>IP address</code> or <code>domain name</code> of your Linux server.</p> </li> <li> <p>Set up Portainer:</p> <p>When you access the Portainer web interface for the first time, you'll be prompted to set up an admin user and password. Follow the on-screen instructions to complete the setup process.</p> </li> </ol> <p>That's it! You have now successfully run Portainer in Docker on your Linux server, and you can start managing your Docker environment through the Portainer web interface.</p> <p>Portainer with Docker</p> <p>To use Docker Swarm mode with Portainer, you need to set up a Docker Swarm cluster and then deploy Portainer as a service within the Swarm. Here's a step-by-step guide on how to do this:</p> <ol> <li> <p>Initialize Docker Swarm:</p> <p>If you haven't already initialized Docker Swarm on your Docker host, you can do so by running the following command in your terminal:</p> bash<pre><code>$ docker swarm init\n</code></pre> <p>This command initializes Docker Swarm mode on the current Docker host and creates a Swarm manager node.</p> </li> <li> <p>Deploy Portainer as a Service:</p> <p>Once Docker Swarm is initialized, you can deploy Portainer as a service within the Swarm. Run the following command to create a Portainer service:</p> bash<pre><code>docker service create \\\n--name portainer \\\n--publish 9000:9000 \\\n--constraint 'node.role == manager' \\\n--mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\\nportainer/portainer-ce\n</code></pre> <p>This command creates a new service named \"portainer\" using the Portainer Community Edition (CE) image. It publishes Portainer's web interface on port 9000 and mounts the Docker socket from the host into the Portainer container, allowing Portainer to interact with the Docker API.</p> </li> <li> <p>Access Portainer Web Interface:</p> <p>Once the Portainer service is deployed, you can access the Portainer web interface by navigating to http://:9000 in your web browser. If you're running Portainer locally, you can use http://localhost:9000.</p> </li> <li> <p>Set Up Portainer:</p> <p>Follow the on-screen instructions to complete the initial setup of Portainer. You'll be prompted to create an admin user, choose a password, and specify whether you want to manage the local Docker environment or a remote Docker Swarm cluster.</p> </li> <li> <p>Connect Portainer to Docker Swarm:</p> <p>If you're managing a remote Docker Swarm cluster, you'll need to specify the Swarm endpoint URL and optionally provide authentication credentials. This allows Portainer to communicate with the Docker Swarm API and manage services, nodes, and other resources within the cluster.</p> </li> <li> <p>Start Managing Services:</p> <p>Once connected, you can start managing Docker Swarm services, nodes, stacks, and other resources using the Portainer web interface. You can create, scale, update, and monitor services, deploy applications using stacks, and perform various administrative tasks.</p> </li> </ol> <p>By following these steps, you can set up and use Docker Swarm mode with Portainer to manage your containerized applications at scale. Make sure to consult the official Portainer documentation for more detailed instructions and best practices.</p> <pre><code>server {\n    listen 80;\n    server_name generic.com.np;\n\n    location / {\n        proxy_pass http://&lt;container-ip&gt;:&lt;container-port&gt;;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"docker/docker/#jenkins","title":"Jenkins","text":"Abstract TheoryPractical <p>Docker Pull Command</p> bash<pre><code>$ docker pull jenkins/jenkins\n</code></pre> <p>After pulling the Docker Jenkins image onto your Linux server, you can start using Jenkins by running the container and accessing its web interface. Here's how you can do it:</p> <ol> <li> <p>Run Jenkins Container:</p> <p>Use the following command to start the Jenkins container:</p> title<pre><code>docker run -d -p 8080:8080 -p 50000:50000 --name jenkins jenkins/jenkins:lts\n</code></pre> <p>Explanation of options:</p> <ul> <li> <p><code>-d</code>: Run the container in detached mode (in the background).</p> </li> <li> <p><code>-p 8080:8080 -p 50000:50000</code>: Map port 8080 on the host to port 8080 inside the container for accessing Jenkins web interface, and map port 50000 for Jenkins agent communication.</p> </li> <li> <p><code>--name jenkins</code>: Assign the name \"jenkins\" to the container.</p> </li> <li> <p><code>jenkins/jenkins:lts</code>: This specifies the Jenkins Docker image to use. In this case, we're using the LTS (Long-Term Support) version.</p> </li> </ul> </li> <li> <p>Access Jenkins Web Interface:</p> <p>Once the Jenkins container is running, you can access its web interface by opening a web browser and navigating to:</p> bash<pre><code>http://your_server_ip:8080\n</code></pre> <p>Replace <code>your_server_ip</code> with the <code>IP address</code> or <code>domain name</code> of your Linux server.</p> </li> <li> <p>Unlock Jenkins:</p> <p>When you access the Jenkins web interface for the first time, you'll be prompted to unlock Jenkins. To do this, you need to retrieve the initial admin password from the Jenkins container logs. Run the following command to view the logs:</p> <pre><code>docker logs jenkins\n</code></pre> <p>Look for the line containing \"Please use the following password to proceed to installation:\", and copy the provided password.</p> </li> <li> <p>Complete Jenkins Setup:</p> <p>Paste the copied password into the Jenkins web interface and click \"Continue\". Follow the on-screen instructions to complete the setup process, including installing recommended plugins.</p> </li> <li> <p>Create Admin User:</p> <p>After plugin installation, you'll be prompted to create an admin user. Provide the required information to create the admin user.</p> </li> <li> <p>Start Using Jenkins:</p> <p>Once you've completed the setup process, you can start using Jenkins to create and manage jobs, automate tasks, and perform continuous integration and continuous delivery (CI/CD) pipelines.</p> </li> </ol> <p>That's it! You've successfully pulled and started the Jenkins Docker container on your Linux server, and you can now begin configuring Jenkins for your development and deployment needs.</p>"},{"location":"docker/docker/#docker-hub","title":"Docker Hub","text":"<p><code>Docker Hub</code> is to Docker what <code>GitHub</code> is to source code.</p> <p>You can think of Docker Hub as being like GitHub.</p> <p>It allows anyone to host its image online and share it publicly or keep it private. To share an image on Docker Hub, you need to do the following:</p> <ul> <li>Create an account on Docker Hub.</li> <li>Log in to the hub on your Docker host.</li> <li>Push your image.</li> </ul> <pre><code>$ docker login\nUsername: how2dock\nPassword:\nEmail: how2dock@gmail.com\nLogin Succeeded\n</code></pre> <ul> <li>Docker Cookbook by S\u00e9bastien Goasguen, pg: 55</li> </ul>"},{"location":"docker/docker/#docker-networking","title":"Docker Networking","text":"<p>As you build your distributed application, services that compose it will need to be able to communicate with each other. These services, running in containers, might be on a single host or on multiple hosts and even across data centers. Therefore container networking is a critical enabler of any Docker-based distributed application.</p>"},{"location":"docker/docker/#downloading-the-first-docker-image","title":"Downloading the first Docker image","text":"<p>The Docker Registry is an application repository that hosts various applications, ranging from basic Linux images to advanced applications. The <code>docker pull</code> subcommand is used to download any number of images from the registry.</p> <pre><code>$ sudo docker pull hello-world\n</code></pre> <p>Once the images have been downloaded, they can be verified using the <code>docker images</code> subcommand, as shown here:</p> <pre><code>$ sudo docker images\n</code></pre>"},{"location":"docker/docker/#running-the-first-docker-container","title":"Running the first Docker container","text":"<pre><code>$ docker run hello-world\n</code></pre> <p>Cool, isn't it? You have set up your first Docker container in no time. In the preceding example, the <code>docker run</code> subcommand has been used to create a container from the hello-world image.</p>"},{"location":"docker/docker/#troubleshooting-docker-containers-or-sudo-service","title":"Troubleshooting Docker containers <code>or</code> sudo service","text":"<p>You can <code>stop</code>, <code>start</code>, and <code>restart</code> the service. For example, to restart it:</p> <pre><code>$ sudo service docker status\n$ sudo service docker restart\n</code></pre>"},{"location":"docker/docker/#certbot-in-linux","title":"certbot in linux","text":"Abstract InstallationSSL Certificate with Certbot <pre><code># There is two ways you can download certbot\n# 1. with PIP\n# 2. with snapd\n\n# step1: Install snapd:\nsudo apt install snapd\n\n# step2: Ensure you have the latest snapd version installed:\nsudo snap install core; sudo snap refresh coreCopied!\n\n# step3: Install Certbot with snapd:\nsudo snap install --classic certbot\n\n# step4: Create a symlink to ensure Certbot runs:\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\n</code></pre> <p>Create an SSL Certificate with Certbot</p> <pre><code># step1: Choose the best option for your needs.\n# Create SSL certs for all domains and configure redirects in the web server:\nsudo certbot --apache\nsudo certbot --nginx\n\n# Create SSL certs for a specified domain (recommended if you\u2019re using your system hostname):\nsudo certbot --apache -d example.com -d www.example.com\n\n# Only install SSL certs:\nsudo certbot certonly --apache\nsudo certbot certonly --nginx\n\n\n# step2: Enter an email address for renewal and security notices.\n# step3: Agree to the terms of service.\n# step4: Specify whether to receive emails from EFF.\n# step5: If prompted, choose whether to redirect HTTP traffic to HTTPS \u2013 1 (no redirect, no further changes to the server) or # 2 (redirect all HTTP requests to HTTPS).\n</code></pre> <ul> <li>How to Install Let\u2019s Encrypt SSL on Ubuntu with Certbot</li> <li>Install Let\u2019s Encrypt SSL Certificates using Certbot</li> </ul> <p>Solved</p> <ul> <li>Issue using certbot with nginx: stackoverflow</li> <li>Whaaaat Are AAAA Records in DNS? youtube</li> </ul> Docker Common Issue Solved Presentation <p>Docker</p> Docker: <code>Host</code> port vs <code>Container</code> port <p>What is left side of port ant right side of port in docker</p> <p>In Docker, when you expose ports for containers, you specify the port mappings using the <code>-p</code> flag or <code>--publish</code> flag when running a container. The syntax is typically <code>hostPort</code>:<code>containerPort</code>.</p> <ul> <li> <p>Left side (<code>hostPort</code>):</p> <p>This is the port on the host machine, the system where Docker is running. It is the port to which you can connect from outside the Docker container to access the services running within the container. If you specify a port on the left side, Docker will bind that port on the host system to the container port specified on the right side.</p> </li> <li> <p>Right side (<code>containerPort</code>):</p> <p>This is the port exposed within the Docker container. It is the port on which your application or service within the container is listening. When Docker starts the container, it will forward any traffic received on the host port (left side) to this port within the container.</p> </li> </ul> <p>For example, if you run a container with <code>-p 8080:80</code>, it means that port <code>80</code> inside the container will be accessible from port <code>8080</code> on the host machine. If you were to access <code>http://localhost:8080</code> on your host machine, Docker would forward that request to port <code>80</code> inside the container.</p> <p>This port mapping mechanism allows Docker containers to communicate with the outside world and for multiple containers to run on the same host without port conflicts.</p> Listen services running on specific port <code>:8000</code> <code>:9000</code> <pre><code># You can use the following commands to find out which processes are using these ports:\nsudo lsof -i :9000\nsudo lsof -i :8080\n</code></pre> <p>Once you identify the processes using these ports, you can decide whether to stop them or reconfigure them to use different ports. After ensuring that the ports are available, you can attempt to start the Nginx service again.</p> Last things you need to remeber in Docker Dind <p>Host os:</p> <ol> <li> <p>Add <code>Jenkins</code> user to the Docker group:</p> <p>On the host machine where Docker is installed, run the following command:</p> bash<pre><code>sudo usermod -aG docker jenkins\n</code></pre> <p>This command adds the Jenkins user to the docker group, granting it permission to interact with the Docker daemon.</p> </li> <li> <p>Ensure permissions on the Docker socket:</p> <p>The Docker daemon socket (<code>/var/run/docker.sock</code>) should be readable and writable by members of the docker group. You can check and     adjust the permissions if needed with the following command:</p> bash<pre><code>sudo chmod 666 /var/run/docker.sock\n</code></pre> </li> <li> <p>Restart Jenkins:</p> <p>Restart the Jenkins service to apply the changes:</p> bash<pre><code>sudo systemctl restart jenkins\n# or\ndocker restart &lt;container_id or container_name&gt;\n</code></pre> </li> </ol> <p>With these changes, the Jenkins user should now have the necessary permissions to execute Docker commands, and <code>you should no longer encounter permission denied errors when running Docker commands from Jenkins job scripts</code>. Make sure to test your Jenkins job again after applying these changes.</p>"},{"location":"docker/docker/#docker-common-issue-solved","title":"Docker Common Issue Solved","text":"Share Docker sockDocker Port Mappingstep1:Final Solution <p>Connect: To share Docker daemon from the host with jenkins nodes</p> <p>To run Docker commands inside Jenkins, especially within a Jenkins instance running inside a Docker container, you have a couple of options:</p> <ol> <li> <p>Docker Socket Binding:</p> bash<pre><code>$ docker run -v /var/run/docker.sock:/var/run/docker.sock &lt;jenkins-image:tag&gt;\n</code></pre> </li> <li> <p>Docker-in-Docker (DinD):</p> bash<pre><code>$ docker run --privileged -v /var/run/docker.sock:/var/run/docker.sock docker:dind\n</code></pre> </li> </ol> <p>How to fix docker: Got permission denied while trying to connect to the Docker daemon socket</p> <p>After an search hour this following solution finaly worked :</p> bash<pre><code>$ sudo chmod 666 /var/run/docker.sock\n</code></pre> <ul> <li>Got permission denied while trying to connect to the Docker daemon socket</li> </ul> <p></p> <p>what is differnce between 8080:80 and 8080:8080. is there any real difference</p> <ul> <li>8080:80</li> </ul> <p>This notation maps port 80 of the container to port 8080 of the host. It means that any traffic directed at port 8080 on the host machine will be forwarded to port 80 inside the Docker container. This is useful when you want to expose a service running inside the container on a standard HTTP port (80) of the host machine.</p> <ul> <li>8080:8080</li> </ul> <p>This notation maps port 8080 of the container to port 8080 of the host. It means that any traffic directed at port 8080 on the host machine will be forwarded to port 8080 inside the Docker container. This is useful when you want to expose a service running inside the container on a non-standard port (8080) of the host machine.</p> <p>In both cases, the first port number (8080) specifies the port on the host machine, and the second port number (80 or 8080) specifies the port inside the Docker container. The port on the host machine is what you use to access the service running inside the container.</p> <p>So, the difference lies in which port on the host machine you want to use to access the service and which port inside the container the service is listening on.</p> <p>so why the jenkins not running on 8080:80 but running on 8080:8080</p> <p>If Jenkins is running inside a Docker container and you've mapped port 8080:8080 but not <code>8080:80</code>, it means that Jenkins is configured to listen for incoming connections on port 8080 inside the container.</p> <p>When you map <code>8080:8080</code>, it indicates that traffic directed to port <code>8080</code> on the host machine should be forwarded to port <code>8080</code> inside the Docker container where Jenkins is running. This setup expects Jenkins to be listening for connections on port <code>8080</code> inside the container.</p> <p>If Jenkins is running on port <code>8080</code> inside the container, mapping <code>8080:8080</code> correctly exposes Jenkins to external traffic on port <code>8080</code> of the host machine.</p> <p>On the other hand, if you were to map <code>8080:80</code>, it would expect Jenkins to be configured to listen on port <code>80</code> inside the container. By default, Jenkins typically runs on port 8080, so mapping <code>8080:80</code> wouldn't work unless you specifically configured Jenkins to listen on port 80 inside the container.</p> <p>Therefore, mapping <code>8080:8080</code> correctly exposes Jenkins running on port <code>8080</code> inside the container to external traffic on port <code>8080</code> of the host machine, which is why it works in your case.</p> <p>Issue Solved</p> <p>Step-by-step instructions to create a Docker image for Jenkins with Docker installed inside it and then run a Jenkins container with the Docker socket mounted from the host:</p> <ol> <li> <p>Create a Dockerfile:</p> <p>Create a file named <code>Dockerfile</code> with the following content:</p> <pre><code>FROM jenkins/jenkins:lts\n\nUSER root\n\n# Install Docker prerequisites\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y apt-transport-https ca-certificates curl gnupg-agent software-properties-common &amp;&amp; \\\n    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\n\n# Install Docker\nRUN curl -fsSL https://get.docker.com -o get-docker.sh &amp;&amp; \\\n    sh get-docker.sh\n\n# Add Jenkins user to Docker group\nRUN usermod -aG docker jenkins\n\nUSER jenkins\n</code></pre> <p>This Dockerfile installs Docker inside the Jenkins container and adds the Jenkins user to the Docker group.</p> </li> <li> <p>Build the Docker Image:</p> <p>Open a terminal and navigate to the directory containing the <code>Dockerfile</code>. Then, run the following command to build the Docker image:</p> <pre><code>docker build -t my-jenkins .\n</code></pre> <p>This command builds the Docker image using the Dockerfile and tags it with the name <code>my-jenkins</code>.</p> </li> <li> <p>Run the Jenkins Container:</p> <p>After the Docker image is built, you can run a Jenkins container with the Docker socket mounted from the host:</p> bash<pre><code>docker run -d \\\n--name jenkins \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-p 8080:8080 -p 50000:50000 \\\nmy-jenkins\n</code></pre> <p>This command starts a Jenkins container named <code>jenkins</code>. It mounts the Docker socket (<code>/var/run/docker.sock</code>) from the host into the container and exposes the Jenkins web interface on port <code>8080</code> and the Jenkins agent communication port on port <code>50000</code>.</p> </li> </ol> <p>With these steps, you have a Jenkins container running with Docker installed inside it, and the Docker socket mounted from the host. This setup allows the Jenkins container to communicate with the Docker daemon on the host and perform Docker-related tasks within Jenkins pipelines or jobs.</p> <p>Docker Socket bind with docker command</p> <pre><code>docker run -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock -v /usr/bin/docker:/usr/bin/docker -v /var/custom_volume/jenkins/:/var/jenkins_home/ --privileged --name b_jenkins 6b7d79a0229e\n</code></pre> <ul> <li>Docker cli excutable file not found</li> <li>docker not found in jenkins pipeline</li> <li>docker not found in jenkins pipeline 2</li> <li>docker: ibm</li> <li>what is docker and why it is darn popular?</li> <li>docker introduction aws</li> </ul>"},{"location":"docker/docker/#docker-presentation","title":"Docker Presentation","text":""},{"location":"docker/docker/#docker-architecture","title":"Docker Architecture","text":"<p>cgroups &amp; namespaces The backbone of the Docker technology are cgroups (short for control groups) and kernel namespaces.</p> <p>With <code>cgroups</code>, the Linux operating system can easily manage and monitor resource allocation for a given process and set resource limits, like CPU, memory, and network limits.</p> <p><code>Namespaces</code> are helpful in isolating process groups from each other. There are six default namespaces in Linux: <code>mnt</code>, <code>IPC</code>, <code>net</code>, <code>usr</code>, <code>pid</code>, and <code>uts</code>. Each container will have its own namespace and processes running inside that namespace, and will not have access to anything outside its namespace.</p> <p></p>"},{"location":"docker/docker/#docker-steps","title":"Docker Steps","text":""},{"location":"docker/docker/#docker-images_1","title":"Docker Images","text":"<p>Where Are Docker Images Stored on the Host Machine? </p> <pre><code>$ docker info\n</code></pre> <p>Now, typically there are two categories of Docker Images</p> <ul> <li>Official Base Images</li> </ul> <p>that are pre-built and can be downloaded or pulled from registries, and</p> <ul> <li>Customized Images</li> </ul> <p>that use base images to create application-specific environments.</p> <p></p> <p></p>"},{"location":"docker/docker/#docker-container_1","title":"Docker Container","text":"<p>The major difference between a <code>container</code> and an <code>image</code> is the top writable layer.</p> <p></p> <p>All changes made to the running container, such as writing new files, modifying existing files, and deleting files, are written to this thin writable container layer.</p> <p>When the container is stopped writable layer remains, and if container was removed writable layer is deleted. So that\u2019s why people say, containers are stateless.</p> <p></p>"},{"location":"docker/docker/#docker-volume_1","title":"Docker Volume","text":"<p>How to Handle Container Storage</p> <p>To make data of any container persistent and accessible outside of the container, Docker provides two options:</p> <ul> <li>Volumes</li> <li>Bind mounts</li> </ul> <p></p>"},{"location":"docker/docker/#docker-port-mapping","title":"Docker Port Mapping","text":""},{"location":"docker/docker/#docker-vs-docker-compose-vs-docker-swarm","title":"Docker vs Docker Compose vs Docker Swarm","text":""},{"location":"docker/docker/#docker-swarm","title":"Docker Swarm","text":""},{"location":"docker/docker/#practical-guide-jenkins","title":"Practical Guide Jenkins","text":"<p>Using Statefull persistant volume </p> <p> </p> <p>Jenkins Tutorial  </p> <p> </p>"},{"location":"docker/docker/#reference","title":"Reference","text":"<p>Linux (<code>Ubuntu</code>)</p> <ul> <li>Install Docker Desktop on Ubuntu</li> <li>how-to-install-docker-on-ubuntu-22-04-20-04 :UPDATED</li> <li>pass tutorial</li> <li>3 Best Ways to Run Docker in Docker Container</li> </ul> <p>Blog</p> <ul> <li>What is a Docker Swarm?</li> <li>Key Differences Between Docker and Docker Swarm </li> </ul> <p>Youtube</p> <ul> <li>Docker Swarm: Simplilearn</li> <li>Docker Swarm Step by Step: Intellipaat</li> <li>Docker vs Kubernetes vs Docker Swarm: Techworld with Nana</li> <li>The EASIEST Docker Swarm Tutorial</li> <li>Docker Compose Tutorial: Programming with Mosh</li> <li>Become a Docker Swarm Expert in just 20 minutes</li> </ul> <p>tmux</p> <ul> <li>tmux resizing pane</li> </ul> <p>Misc <code>youtube</code></p> <ul> <li>what is podman vs docker</li> </ul> <p>Book</p> <ul> <li>Docker Cookbook by S\u00e9bastien Goasguen, pg: 55</li> </ul>"},{"location":"docker/overview/","title":"Overview","text":""},{"location":"docker/react-dockerize-locally/","title":"React Dockerize Locally","text":""},{"location":"docker/react-dockerize-locally/#overview","title":"Overview","text":"<p>Creating a Docker image for your React project and running it on your local machine involves several steps. Below is a step-by-step guide to help you containerize your React project using Docker.</p> <p>How to Dockerize a React App and Run it Locally</p>"},{"location":"docker/react-dockerize-locally/#1-install-docker","title":"1. Install Docker","text":"<p>Before you begin, make sure Docker is installed on your machine. If you haven't installed Docker yet, you can download and install it from Docker's official website.</p>"},{"location":"docker/react-dockerize-locally/#2-prepare-your-react-project","title":"2. Prepare your React project","text":"<p>Assuming you already have a React project, you can follow these steps. If you're starting from scratch, you can create a new React app using Create React App.</p> <pre><code>npx create-react-app my-app\ncd my-app\n</code></pre>"},{"location":"docker/react-dockerize-locally/#3-create-a-dockerfile","title":"3. Create a <code>Dockerfile</code>","text":"<p>The <code>Dockerfile</code> is a text file that contains instructions to build a Docker image for your React application. Create a file named <code>Dockerfile</code> (without any extension) in the root of your React project directory.</p> <p>Here is an example of a <code>Dockerfile</code> for a React app:</p> DockerfileExplanation of the Dockerfile: <pre><code># Step 1: Build the React app\nFROM node:18 AS build\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Install dependencies\nCOPY package.json package-lock.json ./\nRUN npm install\n\n# Copy the source code to the container\nCOPY . .\n\n# Build the React app\nRUN npm run build\n\n# Step 2: Serve the React app using Nginx\nFROM nginx:alpine\n\n# Copy the build folder from the previous step to Nginx's html directory\nCOPY --from=build /app/build /usr/share/nginx/html\n\n# Expose the port that Nginx is running on\nEXPOSE 80\n\n# Start the Nginx server\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>Step 1 (Build React app):</p> <ul> <li><code>FROM node:18 AS build</code>: Use the official Node.js image as the base for the build stage.</li> <li><code>WORKDIR /app</code>: Set the working directory inside the container.</li> <li><code>COPY package.json package-lock.json ./</code>: Copy the package files to the container.</li> <li><code>RUN npm install</code>: Install dependencies.</li> <li><code>COPY . .</code>: Copy the rest of the project files to the container.</li> <li><code>RUN npm run build</code>: Build the React app (produces static files in the <code>/build</code> directory).</li> </ul> <p>Step 2 (Serve with Nginx):</p> <ul> <li><code>FROM nginx:alpine</code>: Use the official Nginx image for serving the static files.</li> <li><code>COPY --from=build /app/build /usr/share/nginx/html</code>: Copy the built static files from the previous build stage into the Nginx container.</li> <li><code>EXPOSE 80</code>: Expose port 80 so that you can access the app from your browser.</li> <li><code>CMD [\"nginx\", \"-g\", \"daemon off;\"]</code>: Start the Nginx server when the container runs.</li> </ul>"},{"location":"docker/react-dockerize-locally/#4-create-a-dockerignore-file","title":"4. Create a .dockerignore file","text":"<p>A <code>.dockerignore</code> file tells Docker which files and directories to ignore when building the image. Create a <code>.dockerignore</code> file in your project root and add the following:</p> <pre><code>node_modules\nbuild\n.dockerignore\nDockerfile\n.git\n.gitignore\n</code></pre> <p>This will prevent unnecessary files from being included in the Docker image, keeping it smaller and more efficient.</p>"},{"location":"docker/react-dockerize-locally/#5-build-the-docker-image","title":"5. Build the Docker image","text":"<p>Once your <code>Dockerfile</code> and <code>.dockerignore</code> are set up, you can build the Docker image.</p> <p>Open your terminal in the project root directory and run the following command:</p> <pre><code>docker build -t my-react-app .\n</code></pre> <p>This will build the Docker image and tag it as <code>my-react-app</code>. The <code>.</code> refers to the current directory (where the <code>Dockerfile</code> is located).</p>"},{"location":"docker/react-dockerize-locally/#6-run-the-docker-container","title":"6. Run the Docker container","text":"<p>Once the image is built, you can run it using the following command:</p> <pre><code>docker run -p 3000:80 my-react-app\n</code></pre> <p>This will run the container, mapping port 3000 on your local machine to port 80 on the container (where Nginx is serving your app). You can access the app by navigating to http://localhost:3000 in your web browser.</p>"},{"location":"docker/react-dockerize-locally/#7-access-your-react-app","title":"7. Access your React app","text":"<p>After running the container, you should be able to visit http://localhost:3000 in your browser and see your React app running.</p>"},{"location":"docker/react-dockerize-locally/#8-stop-and-remove-the-container","title":"8. Stop and remove the container","text":"<p>To stop the container, you can use the following command:</p> <pre><code>docker stop &lt;container_id&gt;\n</code></pre> <p>You can get the <code>container_id</code> by running:</p> <pre><code>docker ps\n</code></pre> <p>If you want to remove the container after stopping it, use:</p> <pre><code>docker rm &lt;container_id&gt;\n</code></pre>"},{"location":"docker/react-dockerize-locally/#9-optional-push-to-docker-hub-for-sharing","title":"9. Optional: Push to Docker Hub (for sharing)","text":"<p>If you want to share your Docker image, you can push it to Docker Hub. First, create an account on [Docker Hub].</p> <p>To push your image:</p> <ol> <li> <p>Tag your image with your Docker Hub username:</p> <pre><code>docker tag my-react-app your-dockerhub-username/my-react-app\n</code></pre> </li> <li> <p>Log in to Docker Hub:</p> <pre><code>docker login\n</code></pre> </li> <li> <p>Push the image to Docker Hub:</p> <pre><code>docker push your-dockerhub-username/my-react-app\n</code></pre> </li> </ol> Summary of the process: <ul> <li>Create a <code>Dockerfile</code> for building and serving the React app.</li> <li>Build the image using <code>docker build</code>.</li> <li>Run the image in a container with <code>docker run</code>.</li> <li>Access your React app locally through the mapped port.</li> </ul> <p>This process should work seamlessly for most React apps. If you have specific configurations or requirements (e.g., environment variables), you may need to adjust the <code>Dockerfile</code> accordingly.</p>"},{"location":"jenkins/jenkins-guide/","title":"Jenkins Guide","text":"<p>jenkins</p> <ol> <li> <p>Adding Restart Policies:</p> <p>You might want to add a restart policy to ensure that the Jenkins container automatically restarts if it crashes or if Docker restarts. This can be done using the <code>--restart</code> flag. For example, you could use <code>--restart</code> unless-stopped to ensure the container restarts unless explicitly stopped.</p> </li> <li> <p>Volume Mounts for Persistence:</p> <p>Jenkins typically stores its data in <code>/var/jenkins_home</code> directory within the container. If you want to persist Jenkins data between container restarts or updates, you can mount a volume from the host machine to this directory. This can be achieved using the <code>-v</code> flag. For example, <code>-v</code> <code>jenkins_home:/var/jenkins_home</code> would mount a volume named <code>jenkins_home</code> to the Jenkins home directory.</p> </li> </ol> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>This command ensures that the Jenkins container runs in detached mode, exposes ports <code>8080</code> and <code>50000</code>, has a restart policy set to \"unless stopped,\" mounts a volume named <code>jenkins_home</code> for data persistence, and uses the LTS version of the Jenkins image.</p> <p>Notes:</p> <p>The <code>-v</code> flag in Docker is used to specify volume mounts. It allows you to create a persistent data volume outside the container and mount it into the container at a specified path.</p> <p>For example, <code>-v</code> <code>/host/directory:/container/directory</code> would mount the directory <code>/host/</code>directory on the host machine into the directory <code>/container/directory</code> within the container.</p> <p>In the context of running Jenkins, you typically want to persist Jenkins data, such as configuration, plugins, and job data, across container restarts. This is achieved by mounting a volume to the <code>/var/jenkins_home</code> directory within the Jenkins container.</p> <p>So, when you use <code>-v</code> <code>jenkins_home:/var/jenkins_home</code>, Docker will create a volume named jenkins_home and mount it into the <code>/var/jenkins_home</code> directory in the container. This ensures that Jenkins data is stored outside the container and persists even if the container is removed or recreated.</p> <p>In summary, when you see <code>-v</code> in a Docker command, it's indicating a volume mount, allowing you to persist data outside the container.</p>"},{"location":"jenkins/jenkins-guide/#docker-with-docker-in-docker-dind","title":"Docker with Docker-in-Docker (DinD):","text":"<p>If you're running Jenkins within a Docker container, you can use Docker-in-Docker (DinD) to allow Jenkins to run Docker commands inside its own Docker containers. However, this approach has security implications and might not be recommended for production use without proper precautions.</p> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>If you want to include Docker-in-Docker (DinD) functionality in your Jenkins container setup, you'll need to bind the Docker socket (/var/run/docker.sock) from the host machine to the Jenkins container. This allows the Jenkins container to communicate with the Docker daemon running on the host machine.</p> <p>Here's the modified command to include the Docker socket binding:</p> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>I've added <code>-v</code> <code>/var/run/docker.sock:/var/run/docker.sock</code> to the command, which binds the Docker socket from the host to the Jenkins container. This allows Jenkins to execute Docker commands inside the container.</p> <p>Now, with this setup, your Jenkins container will have access to Docker commands, allowing you to run Docker builds, start containers, and manage images as part of your Jenkins jobs or pipeline. Make sure to consider the security implications of allowing Jenkins to access the Docker daemon in this way.</p> <p> Solving </p> <p>If you want to pull Docker images within your Jenkins Dockerfile without adding the Docker installation steps, you can indeed simplify your Dockerfile. Here's how you can modify it to only pull Docker images:</p> bash<pre><code>FROM jenkins/jenkins:lts\n\nUSER root\n\n# Add Jenkins user to Docker group\nRUN usermod -aG docker jenkins\n\nUSER jenkins\n</code></pre> <p>With this Dockerfile, you're starting from the official Jenkins LTS image, switching to the root user to add the Jenkins user to the Docker group, and then switching back to the Jenkins user. This will allow Jenkins to pull Docker images without needing to install Docker within the Jenkins container itself.</p> <p>Remember that for this to work, you'll still need to mount the Docker socket from the host machine into the Jenkins container when you run the container. This will allow Jenkins to communicate with the Docker daemon running on the host and pull Docker images. Here's an example of how you can run the container with the Docker socket mounted:</p> bash<pre><code>docker run -d \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  your_custom_jenkins_image\n</code></pre> <p>Replace <code>your_custom_jenkins_image</code> with the name of your custom Jenkins image built from the Dockerfile. With this setup, your Jenkins container will be able to pull Docker images using the Docker CLI on the host machine.</p>"},{"location":"jenkins/jenkins-guide/#docker-images-types","title":"Docker Images Types","text":"<p>In Docker, an <code>image</code> is a lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and configuration files. When you run a Docker image, it creates a container, which is an instance of that image.</p> <p>Whether an image \"runs\" or not depends on what it's designed to do:</p> <ol> <li> <p>Runnable Images:</p> <p>These are images designed to start a process or service that runs continuously or performs some action until explicitly stopped. Examples include web servers, databases, or any other application that provides a service and needs to keep running.</p> </li> <li> <p>One-shot Images:</p> <p>Some images are designed to perform a specific task or action and then exit. These images are typically used for utilities, scripts, or diagnostic tools. They execute their task and then terminate. The <code>hello-world</code> image is an example of this. Other examples might include images for performing backups, data migrations, or other batch operations.</p> </li> </ol> <p>So, all images can be run, but the behavior of what they do when they're run can differ. Some images are meant to continuously run services, while others perform a task and then exit.</p> <p>Notes:</p> <p>Containers need a runnable image to exist. </p>"},{"location":"jenkins/jenkins-guide/#types-of-containers-in-docker","title":"Types of Containers in Docker","text":"<ul> <li>Stateless Containers</li> <li>Stateful Containers</li> <li>Ephemeral Containers</li> </ul>"},{"location":"jenkins/jenkins-guide/#dockerfile-application","title":"Dockerfile application","text":"<p>To create a simple HTML file with \"Hello, World!\" content and then build a Docker image containing this HTML file, you can follow these steps:</p> <ol> <li> <p>Create a simple HTML file named index.html with the \"Hello, World!\" content:</p> html<pre><code>&lt;!-- index.html --&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Hello, World!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> </li> <li> <p>Create a <code>Dockerfile</code> in the same directory to build the Docker image:</p> <pre><code># Dockerfile\nFROM nginx:alpine\nCOPY index.html /usr/share/nginx/html/index.html\n</code></pre> </li> <li> <p>Now, build the Docker image using the docker build command:</p> bash<pre><code>docker build -t hello-world-html .\n</code></pre> <p>This command builds a Docker image named <code>hello-world-html</code> using the Dockerfile in the current directory (<code>.</code>).</p> </li> <li> <p>Once the image is built, you can run a container from it:</p> bash<pre><code>docker run -d -p 8080:80 --name hello-world-container hello-world-html\n</code></pre> <p>This command runs a container from the <code>hello-world-html</code> image, maps port <code>8080</code> on the host to port 80 in the container (<code>-p 8080:80</code>), and gives the container a name (<code>--name hello-world-container</code>).</p> <p>Now, you can visit <code>http://localhost:8080</code> in your web browser to see the \"<code>Hello, World!</code>\" message served by the Docker container running the HTML file.</p> </li> </ol> <p>That's it! You've created a simple HTML file, built a Docker image containing it, and run a Docker container serving the HTML content.</p>"},{"location":"jenkins/jenkins-guide/#pushing-images-to-dockerhub","title":"Pushing <code>images</code> to <code>Dockerhub</code>","text":"<p>To push your Docker image to Docker Hub (which is commonly referred to as Docker's public registry), you need to follow these steps:</p> <ul> <li> <p>Tag your image:</p> <p>Before pushing your image, you need to tag it with your Docker Hub username and the repository name. The format is <code>username/repository:tag</code>. If you haven't tagged your image yet, you can do it using the following command:</p> bash<pre><code>docker tag hello-world-html yourusername/hello-world-html:latest\n</code></pre> <p>Replace <code>hello-world-html</code> with the name of your local image, and <code>yourusername</code> with your Docker Hub username. You can choose any tag you want; <code>latest</code> is commonly used.</p> </li> <li> <p>Log in to Docker Hub:</p> <p>Use the docker login command to log in to your Docker Hub account.</p> bash<pre><code>docker login\n</code></pre> <p>Enter your Docker Hub username and password when prompted.</p> </li> <li> <p>Push your image:</p> <p>After logging in, you can push your image to Docker Hub using the docker push command:</p> bash<pre><code>docker push yourusername/hello-world-html:latest\n</code></pre> <p>Replace <code>yourusername/hello-world-html:latest</code> with the full name of your image, including the tag you used.</p> </li> <li> <p>Verify:</p> <p>Once the push is complete, you can go to your Docker Hub account in your web browser to verify that the image has been successfully pushed.</p> </li> </ul> <p>Your image is now available on Docker Hub and can be pulled by anyone with access to it. Remember that if you plan to share your image publicly, make sure not to include any sensitive information or credentials within the image.</p>"},{"location":"jenkins/jenkins-guide/#reference","title":"Reference","text":"<ul> <li> <p>What is a Docker image?</p> </li> <li> <p>Different Types of Docker Containers</p> </li> <li> <p>Docker images</p> </li> </ul>"},{"location":"jenkins/pocket-devops/","title":"Pocket Devops","text":""},{"location":"jenkins/pocket-devops/#devops","title":"Devops","text":""},{"location":"jenkins/pocket-devops/#running-hello-world-in-docker","title":"Running Hello World in Docker","text":"<p>Problem</p> <p>You have access to a Docker host and want to run your first container. You want to learn the various life cycles of a container. As an example, you want to run a container and echo Hello World in it.</p> <p>Solution</p> <p>Typing docker at the prompt returns the usage of the docker command:</p> <p><code>$ docker</code></p> <p>Usage: <code>docker [OPTIONS] COMMAND [arg...]</code></p> <p>A self-sufficient runtime for linux containers.</p> <pre><code>Unable to find image 'busybox' locally\nbusybox:latest: The image you are pulling has been verified\n511136ea3c5a: Pull complete\ndf7546f9f060: Pull complete\ne433a6c5b276: Pull complete\ne72ac664f4f0: Pull complete\nStatus: Downloaded newer image for busybox:latest\nhello world\n</code></pre> <p>Containers are based on images. An image needs to be passed to the <code>docker run</code> command. In the preceding example, you specify an image called busybox. Docker does not have this image locally and pulls it from a public registry. A registry is a catalog of Docker images that the Docker client can communicate with and download images from. Once the image is pulled, Docker starts a container and executes the echo hello world command. Congratulations\u2014you ran your first container.</p>"},{"location":"jenkins/pocket-devops/#knowing-the-difference-between-containers-and-virtual-machines","title":"Knowing the Difference Between Containers and Virtual Machines","text":"<p>In comparison, with <code>containers</code>, the sharing of the host OS\u2019s kernel with the application means that the overhead of an additional OS is removed.</p>"},{"location":"jenkins/pocket-devops/#dockerfile","title":"Dockerfile","text":"<p>A Dockerfile is a set of instructions that tells Docker how to build an image. A typical Dockerfile is made up of the following:</p> <ul> <li>A <code>FROM</code> instruction that tells Docker what the base image is</li> <li>An <code>ENV</code> instruction to pass an environment variable.</li> <li>A <code>RUN</code> instruction to run some shell commands (for example, install-dependent programs not available in the base image).</li> <li>A <code>CMD</code> or an <code>ENTRYPOINT</code> instruction that tells Docker which executable to run when a container is started.</li> </ul>"},{"location":"jenkins/pocket-devops/#docker-image","title":"Docker Image","text":"<p><code>Docker image</code> is a read-only template that forms the foundation of your application Docker images are created using a <code>series of commands</code>, known as instructions, in the <code>Dockerfile</code>. </p> <p>Breakdown of a <code>.Dockerfile</code></p> <ul> <li>A Docker image starts with a base image, such as Ubuntu.</li> <li>On top of this image, we can add build our application stack adding the packages as and when required.</li> </ul> <p>Notes:</p> <p>On the advanced scale, to keep the image size as low as possible, we can also start with slim packages, such as <code>Alpine</code> or even Scratch, which is Docker\u2019s reserved, minimal starting image for building other images.</p> <p>Every Docker image has an <code>associated tag</code>. Tags typically include <code>names</code> and <code>version labels</code>. While it is not mandatory to associate a version tag with a Docker image name, these tags make it easier to roll back to previous versions. Without a tag name, Docker must fetch the image with the latest tag. You can also provide a tag name to force-fetch a tagged image.</p>"},{"location":"jenkins/pocket-devops/#docker-container","title":"Docker Container","text":"<p>A Docker image, when it\u2019s run in a host computer, spawns a process with its own namespace, known as a Docker container.</p> <p>The <code>main difference between</code> a Docker <code>image</code> and a <code>container</code> is the presence of a thin read/write layer known as the container layer. Any changes to the filesystem of a container, such as writing new files or modifying existing files, are done to this writable container layer than the lower layers.</p> <p>An important aspect to grasp is that when a container is running, the changes are applied to the container layer and when the container is stopped/killed, the container layer is not saved. Hence, all changes are lost. </p> <p>This aspect of containers is not understood very well and for this reason, stateful applications and those requiring persistent data were initially not recommended as containerized applications. However, with <code>Docker Volumes</code>, there are ways to get around this limitation.</p>"},{"location":"jenkins/pocket-devops/#bind-mounts-and-volumes","title":"Bind Mounts and Volumes","text":"<p>Docker provides different ways to mount data into a container from the Docker host: </p> <ul> <li>volumes,</li> <li>bind mounts, &amp; </li> <li>tmpfs volumes.</li> </ul> <p>While <code>tmpfs volumes</code> are stored in the host system\u2019s memory only, <code>bind mounts</code> and <code>volumes</code> are stored in the host filesystem</p>"},{"location":"jenkins/pocket-devops/#docker-engine","title":"Docker Engine","text":"<p>Docker Engine is the core part of Docker. Docker Engine is a client-server application that provides the platform, the runtime, and the tooling for building and managing Docker images, Docker containers, and more. Docker Engine provides the following:</p> <ul> <li>Docker daemon</li> <li>Docker CLI</li> <li>Docker API</li> </ul>"},{"location":"jenkins/pocket-devops/#docker-daemon","title":"Docker Daemon","text":"<p>The Docker daemon is a <code>service</code> that runs in the background of the host computer and handles the heavy lifting of most of the Docker commands. The daemon listens for API requests for creating and managing Docker objects, such as <code>containers</code>, <code>networks</code>, and <code>volumes</code>.</p>"},{"location":"jenkins/pocket-devops/#docker-cli","title":"Docker CLI","text":"<p>Docker CLI is the primary way that you will interact with Docker. Docker CLI exposes a set of commands that you can provide. The Docker CLI forwards the request to Docker daemon, which then performs the necessary work.</p> <p>While the Docker CLI includes a huge variety of commands and sub-commands, the most common commands that we will work with in this book are as mentioned:</p> bash<pre><code>$ docker build\n$ docker pull\n$ docker run\n$ docker exec\n</code></pre>"},{"location":"jenkins/pocket-devops/#docker-api","title":"Docker API","text":"<p>Docker also provides an API for interacting with the Docker Engine. This is particularly useful if there\u2019s a need to create or manage containers from within applications. </p>"},{"location":"jenkins/pocket-devops/#docker-compose","title":"Docker Compose","text":"<p>Docker Compose is a tool for defining and <code>running multi-container applications</code>. Much like how Docker allows you to build an image for your application and run it in your container, Compose use the same images in combination with a definition file (known as the compose file) to build, launch, and run multi-container applications, including dependent and linked containers.</p> <p>The most common use case for Docker Compose is to run applications and their dependent services (such as databases and caching providers) in the same simple, streamlined manner as running a single container application.</p>"},{"location":"jenkins/pocket-devops/#volume","title":"Volume","text":"<p>Docker volumes are the current recommended method of persisting data stored in containers. Volumes are completely managed by Docker and have many advantages over bind mounts:</p>"},{"location":"jenkins/pocket-devops/#docker-volume-subcommands","title":"Docker Volume Subcommands","text":"<p>Docker exposes the Volume API as a series of subcommands.</p> bash<pre><code>$ docker volume create\n\n$ docker volume inspect\n\n$ docker volume ls\n\n$ docker volume prune\n\n$ docker volume rm\n</code></pre>"},{"location":"jenkins/pocket-devops/#hands-on-docker-commands","title":"Hands on Docker <code>Commands</code>","text":"bash<pre><code># Make sure the docke in installed\n$ docker info\n\n# Working with Docker Images\n# listing of the images available locally\n$ docker image ls\n\n# docker inspect command provides a lot of information about the image\n$ docker image inspect hello-world\n\n# Of importance are the image properties Env, Cmd, and Layers,\n# which tell us about these environment variables.\n\n# Env\n$ docker image inspect hello-world | jq .[].Config.Env\n\n# startup command on the container\n$ docker image inspect hello-world | jq .[].Config.Cmd\n\n# layers associated with the image\n$ docker image inspect hello-world | jq .[].RootFS.Layers\n\n#\n$ docker image inspect nginx | jq .[].Config.ExposedPorts\n</code></pre>"},{"location":"blog/archive/2025/","title":"2025","text":""}]}